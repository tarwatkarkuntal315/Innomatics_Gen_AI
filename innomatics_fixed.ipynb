{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf54 Food Delivery Data Integration\n",
    "\n",
    "This notebook integrates data from three different sources:\n",
    "- **orders.csv** - Transactional order data\n",
    "- **users.json** - User master data\n",
    "- **restaurants.sql** - Restaurant master data\n",
    "\n",
    "We'll merge these datasets and create a unified DataFrame for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"\u2705 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load CSV Data (Orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load orders data from CSV\n",
    "orders_df = pd.read_csv('orders.csv')\n",
    "\n",
    "print(f\"\ud83d\udcca Orders DataFrame loaded!\")\n",
    "print(f\"   Shape: {orders_df.shape}\")\n",
    "print(f\"   Columns: {list(orders_df.columns)}\")\n",
    "print(\"\\n\ud83d\udd0d First 5 rows:\")\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load JSON Data (Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load users data from JSON\n",
    "with open('users.json', 'r') as f:\n",
    "    users_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "users_df = pd.DataFrame(users_data)\n",
    "\n",
    "print(f\"\ud83d\udcca Users DataFrame loaded!\")\n",
    "print(f\"   Shape: {users_df.shape}\")\n",
    "print(f\"   Columns: {list(users_df.columns)}\")\n",
    "print(\"\\n\ud83d\udd0d First 5 rows:\")\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load SQL Data (Restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse SQL INSERT statements to extract restaurant data\n",
    "def parse_sql_file(filename):\n",
    "    \"\"\"Parse SQL INSERT statements and return a DataFrame\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        sql_content = f.read()\n",
    "    \n",
    "    # Extract all INSERT statements\n",
    "    pattern = r\"INSERT INTO restaurants VALUES \\((\\d+), '([^']+)', '([^']+)', ([\\d.]+)\\);\"\n",
    "    matches = re.findall(pattern, sql_content)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = []\n",
    "    for match in matches:\n",
    "        data.append({\n",
    "            'restaurant_id': int(match[0]),\n",
    "            'restaurant_name': match[1],\n",
    "            'cuisine': match[2],\n",
    "            'rating': float(match[3])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load restaurants data\n",
    "restaurants_df = parse_sql_file('restaurants.sql')\n",
    "\n",
    "print(f\"\ud83d\udcca Restaurants DataFrame loaded!\")\n",
    "print(f\"   Shape: {restaurants_df.shape}\")\n",
    "print(f\"   Columns: {list(restaurants_df.columns)}\")\n",
    "print(\"\\n\ud83d\udd0d First 5 rows:\")\n",
    "restaurants_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\udccb Data Quality Summary:\\n\")\n",
    "\n",
    "print(\"Orders DataFrame:\")\n",
    "print(orders_df.info())\n",
    "print(f\"\\nMissing values:\\n{orders_df.isnull().sum()}\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nUsers DataFrame:\")\n",
    "print(users_df.info())\n",
    "print(f\"\\nMissing values:\\n{users_df.isnull().sum()}\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nRestaurants DataFrame:\")\n",
    "print(restaurants_df.info())\n",
    "print(f\"\\nMissing values:\\n{restaurants_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Merge the Datasets\n",
    "\n",
    "We'll perform **left joins** to retain all orders:\n",
    "1. Merge orders with users on `user_id`\n",
    "2. Merge result with restaurants on `restaurant_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge orders with users\n",
    "print(\"\ud83d\udd17 Merging orders with users...\")\n",
    "merged_df = orders_df.merge(users_df, on='user_id', how='left')\n",
    "print(f\"   After user merge: {merged_df.shape}\")\n",
    "\n",
    "# Step 2: Merge with restaurants (using suffixes to distinguish duplicate columns)\n",
    "print(\"\ud83d\udd17 Merging with restaurants...\")\n",
    "final_dataset = merged_df.merge(\n",
    "    restaurants_df, \n",
    "    on='restaurant_id', \n",
    "    how='left',\n",
    "    suffixes=('_order', '_restaurant')\n",
    ")\n",
    "print(f\"   After restaurant merge: {final_dataset.shape}\")\n",
    "\n",
    "print(\"\\n\u2705 Final dataset created successfully!\")\n",
    "print(f\"\\n\ud83d\udcca Final Dataset Shape: {final_dataset.shape}\")\n",
    "print(f\"   Total Orders: {len(final_dataset)}\")\n",
    "print(f\"   Total Columns: {len(final_dataset.columns)}\")\n",
    "print(f\"\\nColumns: {list(final_dataset.columns)}\")\n",
    "print(\"\\n\ud83d\udca1 Note: 'restaurant_name_order' is from orders.csv, 'restaurant_name_restaurant' is from restaurants.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Preview Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 10 rows\n",
    "final_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "final_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Final Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save the final dataset to CSV\n",
    "# final_dataset.to_csv('final_food_delivery_dataset.csv', index=False)\n",
    "# print(\"\u2705 Final dataset saved to 'final_food_delivery_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udfaf Your Analysis Here\n",
    "\n",
    "The `final_dataset` DataFrame is ready for your exploratory data analysis!\n",
    "\n",
    "**Happy Analyzing! \ud83d\ude80**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Which city has the highest revenue from Gold members?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Gold members only\n",
    "gold_members = final_dataset[final_dataset['membership'] == 'Gold']\n",
    "\n",
    "# Calculate total revenue by city for Gold members\n",
    "revenue_by_city = gold_members.groupby('city')['total_amount'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TOTAL REVENUE BY CITY (GOLD MEMBERS ONLY)\")\n",
    "print(\"=\" * 60)\n",
    "print(revenue_by_city)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"ANSWER: {revenue_by_city.idxmax()} has the highest revenue\")\n",
    "print(f\"Revenue: Rs. {revenue_by_city.max():,.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom analysis here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}